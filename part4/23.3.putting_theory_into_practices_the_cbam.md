23.3 Putting Theory into Practice: The CBAM
===

With the concepts in place we can now describe techniques for putting them into practice, in the form of a method we call the Cost Benefit Analysis Method (CBAM). As we describe the method, remember that, like all of our stakeholder-based methods, it could take any of the forms for stakeholder interaction that we discussed in the introduction to Part III.

# Practicalities of Utility Curve Determination

To build the utility-response curve, we first determine the quality attribute levels for the best-case and worst-case situations. The best-case quality attribute level is that above which the stakeholders foresee no further utility. For example, a system response to the user of 0.1 second is perceived as instantaneous, so improving it further so that it responds in 0.03 second has no additional utility. Similarly, the worst-case quality attribute level is a minimum threshold above which a system must perform; otherwise it is of no use to the stakeholders. These levels—best-case and worst-case—are assigned utility values of 100 and 0, respectively. We then determine the current and desired utility levels for the scenario. The respective utility values (between 0 and 100) for various alternative strategies are elicited from the stakeholders, using the best-case and worst-case values as reference points. For example, our current design provides utility about half as good as we would like, but an alternative strategy being considered would give us 90 percent of the maximum utility. Hence, the current utility level is set to 50 and the desired utility level is set to 90.

In this manner the utility curves are generated for all of the scenarios.

> **Show Business or Accounting?**
> 
> As software architects, what kind of business are we in? One of Irving Berlin’s most famous songs is entitled “There’s No Business Like Show Business.” David Letterman, riffing off this song title, once quipped, “There’s no business like show business, but there are several businesses like accounting.”
> 
> How should we think of ourselves, as architects? Consider two more quotations from famous business leaders:
> 
> > I never get the accountants in before I start up a business. It’s done on gut feeling. —Richard Branson
> >
> > It has been my experience that competency in mathematics, both in numerical manipulations and in understanding its conceptual foundations, enhances a person’s ability to handle the more ambiguous and qualitative relationships that dominate our day-to-day financial decision-making. —Alan Greenspan
> 
> Architectures are at the fulcrum of a set of business, social, and technical decisions. A poor decision in any dimension can be disastrous for an organization. A decision in any one dimension is influenced by the other dimensions. So in our roles as architects, which are we, Alan Greenspan or Richard Branson?
> 
> My claim is that, as an industry, we in software are more like Richard Branson. We make decisions that have enormous economic consequences on a gut feeling, without ever examining their financial consequences in a disciplined way. This might be OK if you are an intuitive genius, but it doesn’t work well for most of us. Engineering is about making good decisions in a rational, predictable way. For this we need methods.
> 
> —RK

# Practicalities of Weighting Determination

One method of weighting the scenarios is to prioritize them and use their priority ranking as the weight. So for N scenarios, the highest priority one is given a weight of 1, the next highest is given a weight of (N–1)/N, and so on. This turns the problem of weighting the scenarios into one of assigning priorities.

The stakeholders can determine the priorities through a variety of voting schemes. One simple method is to have each stakeholder prioritize the scenarios (from 1 to N) and the total priority of the scenario is the sum of the priorities it receives from all of the stakeholders. This voting can be public or secret.

Other schemes are possible. Regardless of the scheme used, it must make sense to the stakeholders and it must suit their culture. For example, in some corporate environments, everything is done by consensus. In others there is a strict hierarchy, and in still others decisions are made in a democratic fashion. In the end it is up to the stakeholders to make sure that the scenario weights agree with their intuition.

# Practicalities of Cost Determination

One of the shortcomings of the field of software architecture is that there are very few cost models for various architectural strategies. There are many software cost models, but they are based on overall system characteristics such as size or function points. These are inadequate to answer the question of how much does it cost to, for example, use a publish-subscribe pattern in a particular portion of the architecture. There are cost models that are based on complexity of modules (by function point analysis according to the requirements assigned to each module) and the complexity of module interaction, but these are not widely used in practice. More widely used in practice are corporate cost models based on previous experience with the same or similar architectures, or the experience and intuition of senior architects.

Lacking cost models whose accuracy can be assured, architects often turn to estimation techniques. To proceed, remember that an absolute number for cost isn’t necessary to rank candidate architecture strategies. You can often say something like “Suppose strategy A costs $x. It looks like strategy B will cost $2x, and strategy C will cost $0.5x.” That’s enormously helpful. A second approach is to use very coarse estimates. Or if you lack confidence for that degree of certainty, you can say something like “Strategy A will cost a lot, strategy B shouldn’t cost very much, and strategy C is probably somewhere in the middle.”

# CBAM

Now we describe the method we use for economic analysis: the Cost Benefit Analysis Method. CBAM has for the most part been applied when an organization was considering a major upgrade to an existing system and they wanted to understand the utility and value for cost of making the upgrade, or they wanted to choose between competing architectural strategies for the upgrade. CBAM is also applicable for new systems as well, especially for helping to choose among competing strategies. Its key concepts (quality attribute response curves, cost, and utility) do not depend on the setting.

**Steps**. A process flow diagram for the CBAM is given in Figure 23.3. The first four steps are annotated with the relative number of scenarios they consider. That number steadily decreases, ensuring that the method concentrates the stakeholders’ time on the scenarios believed to be of the greatest potential in terms of VFC.

This description of CBAM assumes that a collection of quality attribute scenarios already exists. This collection might have come from a previous elicitation exercise such as an ATAM exercise (see Chapter 21) or quality attribute utility tree construction (see Chapter 16).

The stakeholders in a CBAM exercise include people who can authoritatively speak to the utility of various quality attribute responses, and probably include the same people who were the source of the quality attribute scenarios being used as input. The steps are as follows:

1. _Collate scenarios_. Give the stakeholders the chance to contribute new scenarios. Ask the stakeholders to prioritize the scenarios based on satisfying the business goals of the system. This can be an informal prioritization using a simple scheme such as “high, medium, low” to rank the scenarios. Choose the top one-third for further study.
2. _Refine scenarios_. Refine the scenarios chosen in step 1, focusing on their stimulus-response measures. Elicit the worst-case, current, desired, and best-case quality attribute response level for each scenario. For example, a refined performance scenario might tell us that worst-case performance for our system’s response to user input is 12 seconds, the best case is 0.1 seconds, and our desired response is 0.5 seconds. Our current architecture provides a response of 1.5 seconds:

  Scenario | Worst Case | Current | Desired | Best Case
  ---|---|---|---|---
  Scenario #17: Response to user input | 12 seconds | 1.5 seconds | 0.5 seconds | 0.1 seconds
  … |

3. _Prioritize scenarios_. Prioritize the refined scenarios, based on stakeholder votes. You give 100 votes to each stakeholder and have them distribute the votes among the scenarios, where their voting is based on the desired response value for each scenario. Total the votes and choose the top 50 percent of the scenarios for further analysis. Assign a weight of 1.0 to the highest-rated scenario; assign the other scenarios a weight relative to the highest rated. This becomes the weighting used in the calculation of a strategy’s overall benefit.
Make a list of the quality attributes that concern the stakeholders.
4. Assign utility. Determine the utility for each quality attribute response level (worst-case, current, desired, best-case) for the scenarios from step 3. You can conveniently capture these utility curves in a table (one row for each scenario, one column for each of the four quality attribute response levels). Continuing our example from step 2, this step would assign utility values from 1 to 100 for each of the latency values elicited for this scenario in step 2:

Scenario | Worst Case | Current | Desired | Best Case
---|---|---|---|---
Scenario #17: Response to user input | 12 seconds | 1.5 seconds | 0.5 seconds | 0.1 seconds
. | Utility 5 | Utility 50 | Utility 80 | Utility 85

5. _Map architectural strategies to scenarios and determine their expected quality attribute response levels_. For each architectural strategy under consideration, determine the expected quality attribute response levels that will result for each scenario.
6. _Determine the utility of the expected quality attribute response levels by interpolation_. Using the elicited utility values (that form a utility curve), determine the utility of the expected quality attribute response level for the architectural strategy. Do this for each relevant quality attribute enumerated in step 3. For example, if we are considering a new architectural strategy that would result in a response time of 0.7 seconds, we would assign this a utility proportionately between 50 (which it exceeds) and 80 (which it doesn’t exceed).

   The formula for interpolation between two data points $(x_{a}, y_{a})$ and $(x_{b}, y_{b})$ is given by:

   $ y = y_{a} + (y_{b} - y_{a}) \frac{(x - x_{a})}{(x_{b} - x_{a})} $

   For us, the $x$ values are the quality attribute response levels and the $y$ values are the utility values. So, employing this formula, the utility value of a 0.7-second response time is 74.

7. _Calculate the total benefit obtained from an architectural strategy_. Subtract the utility value of the “current” level from the expected level and normalize it using the votes elicited in step 3. Sum the benefit due to a particular architectural strategy across all scenarios and across all relevant quality attributes.
8. _Choose architectural strategies based on VFC subject to cost and schedule constraints_. Determine the cost and schedule implications of each architectural strategy. Calculate the VFC value for each as a ratio of benefit to cost. Rank-order the architectural strategies according to the VFC value and choose the top ones until the budget or schedule is exhausted.
9. _Confirm results with intuition_. For the chosen architectural strategies, consider whether these seem to align with the organization’s business goals. If not, consider issues that may have been overlooked while doing this analysis. If there are significant issues, perform another iteration of these steps.

![](fig.23.3)

FIGURE 23.3 Process flow diagram for the CBAM

> **Computing Benefit for Architectural Variation Points**
> 
> This chapter is about calculating the cost and benefit of competing architectural options. While there are plenty of metrics and methods to measure cost, usually as some function of complexity, benefit is more slippery. CBAM uses an assemblage of stakeholders to work out jointly what utility each architectural option will bring with it. At the end of the day, CBAM’s measures of utility are subjective, intuitive, and imprecise. That’s all right; stakeholders seldom are able to express benefit any better than that, and so CBAM takes what stakeholders know and formulates it into a justified choice. That is, CBAM elicits inputs that are imprecise, because nothing better is available, and does the best that can be done with them.
> 
> As a counterpoint to CBAM, there is one area of architecture in which the architectural options are of a specific variety: product-line architectures. In Chapter 25, you’ll be introduced to software architectures that serve for an entire family of systems. The architect introduces variation points into the architecture, which are places where it can be quickly tailored in preplanned ways so that it can serve each of a variety of different but related products. In the product-line context, the major architectural option is whether to build a particular variation point in the architecture. Doing so isn’t free; otherwise, every product-line architecture would have an infinitude of variation points. So the question becomes: When will adding a variation point pay off?
> 
> CBAM would work for this case as well; you could ask the product line’s stakeholders what the utility of a new variation point would be, vis-à-vis other options such as including a different variation point instead, or none at all. But in this case, there is a quantitative formula to measure the benefit. John McGregor of Clemson University has long been interested in the economics of software product lines, and along with others (including me) invented SIMPLE, a cost-modeling language for software product lines. SIMPLE is great at estimating the cost of product-line options, but not so great at estimating its benefits. Recently, McGregor took a big step toward remedying that.
> 
> Here is his formula for modeling the marginal value of building in an additional variation point to the architecture:
>
> $ v_{i}(t,T) = max(0, -E \left [ \sum_{\tau =t}^{T} c_{i}(\tau)e^{-r(\tau)-t} \right ] + \rho_{i,T}E \left [ \sum_{k}^{} max(0, \sum_{\tau=T}^{T^{*}} X_{i,k} (\tau) e^{-r(\tau - t)} ) \right ] ) $
>
> Got that? No? Right, me neither. But we can understand it if we build it up from pieces.
> 
> The equation says (as all value equations do) that value is benefit minus cost, and so those are the two terms.
> 
> The first term measures the expected cost of building variation point $i$ over a time period from now until time $T$ (some far-off horizon of interest such as fielding your fifth system or getting your next round of venture capital funding). The function $c_{i} (τ)$ measures the cost of building variation point $i$ at time $τ$; it’s evaluated using conventional cost-estimating techniques for software. The e factor is a standard economic term that accounts for the net present value of money; r is the assumed current interest rate. This is summed up over all time between now and $T$ , and made negative to reflect that cost is negative value. So here’s the first term decomposed:
>
> ![](fig.23.3.x)
>
> The second term evaluates the benefit. The function $X_{i,k} (τ)$ is the key; it measures the value of the variation point in the k th product of the product line. This is equal to the marginal value of the variation point to the $k$th product, minus the cost of using (exercising) the variation point in that $k$th product. That first part is the hardest part to come by, but your marketing department should be able to help by expressing the marginal value in terms of the additional products that the variation point would enable you to build and how much revenue each would bring in. (That’s what marketing departments are paid to figure out.)
>
> ![](fig.23.3.y)
>
> To the function $X$ we apply the same factor as before to account for the net present value of money, sum it up over all time periods between now and $T$ , and make it nonnegative:
>
> ![](fig.23.3.z)
>
> Then we sum that up over all products $k$ in the product line and multiply it by the probability that the variation point will in fact be ready by the time it’s needed:
>
> ![](fig.23.3.a)
>
> Add the two terms together and there you have it. It’s easy to put this in a spreadsheet that calculates the result given the relevant inputs, and it provides a quantitative measurement to help guide selection of architectural options—in this case, introduction of variation points to support a product line.
> 
> —PCC
