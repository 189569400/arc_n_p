26.6 Architecting in a Cloud Environment
===

Now we take the point of view of an architect who is designing a system to exe-
cute in the cloud. In some ways, the cloud is a platform, and architecting a system
to execute in the cloud, especially using IaaS, is no different than architecting for
any other distributed platform. That is, the architect needs to pay attention to us-
ability, modifiability, interoperability, and testability, just as he or she would for
any other platform. The quality attributes that have some significant differences
are security, performance, and availability.

Security

Security, as always, has both technical and nontechnical aspects. The nontechnical
aspects of security are items such as what trust is placed in the cloud provider, what
physical security does the cloud provider utilize, how are employees of the cloud
provider screened, and so forth. We will focus on the technical aspects of security.

Applications in the cloud are accessed over the Internet using standard Inter-
net protocols. The security and privacy issues deriving from the use of the Inter-
net are substantial but no different from the security issues faced by applications
not hosted in the cloud. The one significant security element introduced by the
cloud is multi-tenancy. Multi-tenancy means that your application is utilizing a
virtual machine on a physical computer that is hosting multiple virtual machines.
If one of the other tenants on your machine is malicious, what damage can they
do to you?

There are four possible forms of attack utilizing multi-tenancy:

1. _Inadvertent information sharing_. Each tenant is given a set of virtual resources. Each virtual resource is mapped to some physical resource. It is possible that information remaining on a physical resource from one tenant may “leak” to another tenant.
2. _A virtual machine “escape.”_ A virtual machine is isolated from other virtual machines through the use of a distinct address space. It is possible, however, that an attacker can exploit software errors in the hypervisor to access information they are not entitled to. Thus far, such attacks are extremely rare.
3. _Side-channel attacks_. It is possible for a malicious attacker to deduce information about keys and other sensitive information by monitoring the timing activity of the cache. Again, so far, this is primarily an academic exercise.
4. _Denial-of-service attacks_. Other tenants may use sufficient resources on the host computer so that your application is not able to provide service.

Some providers allow customers to reserve entire machines for their exclusive use. Although this defeats some of the economic benefits of using the cloud, it is a mechanism to prevent multi-tenancy attacks. An organization should consider possible attacks when deciding which applications to host in the cloud, just as they should when considering any hosting option.

Performance

The instantaneous computational capacity of any virtual machine will vary depending on what else is executing on that machine. Any application will need to monitor itself to determine what resources it is receiving versus what it will need.

One virtue of the cloud is that it provides an elastic host. Elasticity means that additional resources can be acquired as needed. An additional virtual machine, for example, will provide additional computational capacity. Some cloud providers will automatically allocate additional resources as needed, whereas other providers view requesting additional resources as the customer’s responsibility.

Regardless of whether the provider automatically allocates additional resources, the application should be self-aware of both its current resource usage and its projected resource usage. The best the provider can do is to use general algorithms to determine whether there is a need to allocate or free resources. An application should have a better model of its own behavior and be better equipped to do its own allocation or freeing of resources. In the worst case, the application can compare its predictions to those of the provider to gain insight into what will happen. It takes time for the additional resources to be allocated and freed. The freeing of resources may not be instantaneously reflected in the charging algorithm used by the provider, and that charging algorithm also needs to be considered when allocating or freeing resources.

Availability

The cloud is assumed to be always available. But everything can fail. A virtual machine, for example, is hosted on a physical machine that can fail. The virtual network is less likely to fail, but it too is fallible. It behooves the architect of a system to plan for failure.

The service-level agreement that Amazon provides for its EC2 cloud service provides a 99.95 percent guarantee of service. There are two ways of looking at that number: (1) That is a high number. You as an architect do not need to worry about failure. (2) That number indicates that the service may be unavailable for .05 percent of the time. You as an architect need to plan for that .05 percent.

Netflix is a company that streams videos to home television sets, and its reliability is an important business asset. Netflix also hosts much of its operation on Amazon EC2. On April 21, 2011, Amazon EC2 suffered a four-day sporadic outage. Netflix customers, however, were unaware of any problem.

Some of the things that Netflix did to promote availability that served them well during that period were reported in their tech blog. We discussed their Simian Army in Chapter 10. Some of the other things they did were applications of availability tactics that we discussed in Chapter 5.

* _Stateless services_. Netflix services are designed such that any service instance can serve any request in a timely fashion, so if a server fails, requests can be routed to another service instance. This is an application of the spare tactic, because the other service instance acts as a spare.
* _Data stored across zones_. Amazon provides what they call “availability zones,” which are distinct data centers. Netflix ensured that there were multiple redundant hot copies of the data spread across zones. Failures were retried in another zone, or a hot standby was invoked. This is an example of the active redundancy tactic.
* _Graceful degradation_. The general principles for dealing with failure are applications of the degradation or the removal from service tactic:
   * Fail fast: Set aggressive timeouts such that failing components don’t make the entire system crawl to a halt.
   * Fallbacks: Each feature is designed to degrade or fall back to a lower quality representation.
   * Feature removal: If a feature is noncritical, then if it is slow it may be removed from any given page.

> **The CAP Theorem**
> 
> The CAP theorem—created by Eric Brewer at UC Berkeley—emerged over a decade ago. Unlike most theories postulated by academics, this one did not sink into obscurity but rather has grown in renown and influence since then. The theory states that there are three important properties of a distributed system managing shared data. These are the following:
>
> * Consistency (C): the data will be consistent throughout the distributed system.
> * Availability (A): the data will be highly available.
> * Partitioning (P): the system will tolerate network partitioning.
>
> And the theory further states that no system can achieve all of these properties simultaneously; the best we can hope for is to satisfy two out of three while sacrificing (to some extent) the third property. Brewer explains it thus:
>
> > The easiest way to understand CAP is to think of two nodes on opposite sides of a partition. Allowing at least one node to update state will cause the nodes to become inconsistent, thus forfeiting C. Likewise, if the choice is to preserve consistency, one side of the partition must act as if it is unavailable, thus forfeiting A. Only when nodes communicate is it possible to preserve both consistency and availability, thereby forfeiting P.
>
> In fact, there is really another important facet to the CAP theorem that has come to dominate the engineering challenge: latency. It wasn’t part of the original acronym (although CLAP is certainly catchy), but a concern for latency now infuses much of the discussion of the tradeoffs in implement-ing NoSQL databases.
>
> Creators of large-scale distributed NoSQL databases are constantly faced with tradeoffs. These days no one believes that you simply choose two of the three properties of CAP; the decisions are far richer and more subtle than that. For example, designers of these systems like to speak of “eventual consistency”—partitions are allowed to become inconsistent on a regular basis, but with bounds that are carefully engineered and monitored. They might want to specify that no more than x percent of the data should be stale at any given time, and it should not take more than y seconds to restore consistency (on average, or in the worst case). Another common tradeoff seen in practice is that availability and latency are typically favored over consistency. That is, a Facebook user should get quick response from the system, even if their newsfeed is slightly stale.
>
> All of this adds complexity to the system. The designer has to choose between faster/less consistent and slower/more consistent (as well as a host of other quality issues). And the mechanisms for achieving eventual consistency—caching, replication, message retries, timeouts, and so forth—are themselves nontrivial. Consistency, partitioning, latency, and availability are four qualities that can be traded off with NoSQL databases. In addition, other quality attributes—interoperability, security, and so forth—also add complexity, and so the tradeoffs involved can get more and more complicated.
>
> Alas, this is, increasingly, the world that we live in. Systems with global reach and enormous bases of distributed data are not going away anytime soon. So as architects we need to be prepared to deal with tradeoffs and complexities for the foreseeable future.
>
> —RK
