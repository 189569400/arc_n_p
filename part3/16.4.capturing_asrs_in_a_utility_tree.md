16.4 Capturing ASRs in a Utility Tree
===

As we have seen, ASRs can be extracted from a requirements document, captured from stakeholders in a workshop such as a QAW, or derived from business goals. It is helpful to record them in one place so that the list can be reviewed, refer-enced, used to justify design decisions, and revisited over time or in the case of major system changes.

To recap, an ASR must have the following characteristics:

* _A profound impact on the architecture._ Including this requirement will very likely result in a different architecture than if it were not included.
* _A high business or mission value._ If the architecture is going to satisfy this requirement—potentially at the expense of not satisfying others—it must be of high value to important stakeholders.

Using a single list can also help evaluate each potential ASR against these criteria, and to make sure that no architectural drivers, stakeholder classes, or business goals are lacking ASRs that express their needs.

>
> **A Method for Capturing Business Goals**
> 
> PALM is a seven-step method, nominally carried out over a day and a half in a workshop attended by architects and stakeholders who can speak to the business goals of the organizations involved. The steps are these:
>
> 1. _PALM overview presentation._ Overview of PALM, the problem it solves, its steps, and its expected outcomes.
> 2. _Business drivers presentation._ Briefing of business drivers by project management. What are the goals of the customer organization for this system? What are the goals of the development organization? This is normally a lengthy discussion that allows participants to ask questions about the business goals as presented by project management.
> 3. _Architecture drivers presentation._ Briefing by the architect on the driving business and quality attribute requirements: the ASRs.
> 4. _Business goals elicitation._ Using the standard business goal categories to guide discussion, we capture the set of important business goals for this system. Business goals are elaborated and expressed as scenarios. We consolidate almost-alike business goals to eliminate duplication. Participants then prioritize the resulting set to identify the most important goals.
> 5. _Identification of potential quality attributes from business goals._ For each important business goal scenario , participants describe a quality attribute that (if architected into the system) would help achieve it. If the QA is not already a requirement, this is recorded as a finding.
> 6. _Assignment of pedigree to existing quality attribute drivers._ For each architectural driver named in step 3, we identify which business goals it is there to support. If none, that’s recorded as a finding. Otherwise, we establish its pedigree by asking for the source of the quantitative part. For example: Why is there a 40-millisecond performance requirement? Why not 60 milliseconds? Or 80 milliseconds?
> 7. _Exercise conclusion._ Review of results, next steps, and participant feedback.

Architects can use a construct called a utility tree for all of these purposes. A utility tree begins with the word “utility” as the root node. Utility is an expression of the overall “goodness” of the system. We then elaborate this root node by listing the major quality attributes that the system is required to exhibit. (We said in Chap-ter 4 that quality attribute names by themselves were not very useful. Never fear: we are using them only as placeholders for subsequent elaboration and refinement!)

Under each quality attribute, record a specific refinement of that QA. For example, performance might be decomposed into “data latency” and “transac-tion throughput.” Or it might be decomposed into “user wait time” and “time to refresh web page.” The refinements that you choose should be the ones that are relevant to your system. Under each refinement, record the appropriate ASRs (usually expressed as QA scenarios).

Some ASRs might express more than one quality attribute and so might ap-pear in more than one place in the tree. That is not necessarily a problem, but it could be an indication that the ASR tries to cover too much diverse territory. Such ASRs may be split into constituents that each attach to smaller concerns.

Once the ASRs are recorded and placed in the tree, you can now evaluate them against the two criteria we listed above: the business value of the candidate ASR and the architectural impact of including it. You can use any scale you like, but we find that a simple “H” (high), “M” (medium), and “L” (low) suffice for each criterion.

For business value, High designates a must-have requirement, Medium is for a requirement that is important but would not lead to project failure were it omitted. Low describes a nice requirement to have but not something worth much effort.

For architectural impact, High means that meeting this ASR will profoundly affect the architecture. Medium means that meeting this ASR will somewhat af-fect the architecture. Low means that meeting this candidate ASR will have little effect on the architecture.

Table 16.5 shows a portion of a sample utility tree drawn from a health care ap-plication called Nightingale. Each ASR is labeled with a pair of “H,” “M,” and “L” values indicating (a) the ASR’s business value and (b) its effect on the architecture.

Once you have a utility tree filled out, you can use it to make important checks. For instance:

* A QA or QA refinement without any ASR is not necessarily an error or omission that needs to be rectified, but it is an indication that attention should be paid to finding out for sure if there are unrecorded ASRs in that area. 
* ASRs that rate a (H,H) rating are obviously the ones that deserve the most attention from you; these are the most significant of the significant require-ments. A very large number of these might be a cause for concern about whether the system is achievable.
* Stakeholders can review the utility tree to make sure their concerns are ad-dressed. (An alternative to the organization we have described here is to use stakeholder roles rather than quality attributes as the organizing rule under “Utility.”)

TABLE 16.5 Tabular Form of the Utility Tree for the Nightingale ATAM Exercise

Quality Attribute | Attribute Refinement | ASR
---|---|---
Performance | Transaction response time | A user updates a patient’s account in response to a change-of-address notification while the system is under peak load, and the transaction completes in less than 0.75 second. (H,M) <br>A user updates a patient’s account in response to a change-of-address notification while the system is under double the peak load, and the transaction completes in less than 4 seconds. (L,M)
. | Throughput | At peak load, the system is able to complete 150 normalized transactions per second. (M,M)
Usability | Proficiency training | A new hire with two or more years’ experience in the business becomes proficient in Nightingale’s core functions in less than 1 week. (M,L) <br>A user in a particular context asks for help, and the system provides help for that context, within 3 seconds. (H,M)
. | Normal operations | A hospital payment officer initiates a payment plan for a patient while interacting with that patient and completes the process without the system introducing delays. (M,M)
Configurability | User-defined changes | A hospital increases the fee for a particular service. The configuration team makes the change in 1 working day; no source code needs to change. (H,L)
Maintainability | Routine changes | A maintainer encounters search- and response-time deficiencies, fixes the bug, and distributes the bug fix with no more than 3 person-days of effort. (H,M) <br>A reporting requirement requires a change to the report-generating metadata. Change is made in 4 person-hours of effort. (M,L)
. | Upgrades to commercial components | The database vendor releases a new version that must be installed in less than 3 person-weeks. (H,M)
Extensibility | Adding new product | A product that tracks blood bank donors is created within 2 person-months. (M,M)
Security | Confidentiality | A physical therapist is allowed to see that part of a patient’s record dealing with orthopedic treatment but not other parts nor any financial information. (H,M)
. | Integrity | The system resists unauthorized intrusion and reports the intrusion attempt to authorities within 90 seconds. (H,M) 
Availability | No downtime | The database vendor releases new software, which is hot-swapped into place, with no downtime. (H,L) <br>The system supports 24/7 web-based account access by patients. (L,L)
